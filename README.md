
![NerD Banner](images/banner.jpg)

# NerD ğŸ§ ğŸ“¸

**NerD** is a multitask natural language processing system that performs **Named Entity Recognition (NER)** and **Sentiment Analysis (SA)** simultaneously, enriched by **Image Captioning**. Designed to process and analyze multimodal content (text + image), NerD extracts structured information and sentiment context from real-world data, such as news or social media posts.

This project was developed as part of a **Deep Learning and NLP** course at the **Universidad Pontificia Comillas, ICAI**, within the **Engineering Mathematics** program.

## ğŸ“œ Table of Contents
- [ğŸ“Œ Project Overview](#-project-overview)
- [ğŸ› ï¸ Installation](#ï¸-installation)
- [ğŸš€ How to Use](#-how-to-use)
- [ğŸ“‚ Project Structure](#-project-structure)
- [ğŸ§  Technologies Used](#-technologies-used)
- [ğŸ™Œ Credits](#-credits)

## ğŸ“Œ Project Overview

NerD combines multiple deep learning components to perform robust analysis of multimodal data:

### ğŸ” Multitask Learning Model
- A custom **BiLSTMTagger** model performs both:
  - **Token-level Named Entity Recognition (NER)**
  - **Sentence-level Sentiment Analysis (SA)**
- Shared **BiLSTM encoder** for feature extraction.
- Optimized using a combination of `CrossEntropyLoss` for NER and `BCELoss` for SA.
- Model selection based on validation performance.

### ğŸ–¼ï¸ Image Captioning Integration
- A pretrained model from **Hugging Face** generates captions from input images.
- These captions are incorporated into the input pipeline to enhance entity and sentiment prediction.

### ğŸ“Š Dataset Curation
- Reformatted and preprocessed **MultiNERD** and other datasets.
- Auto-labeled sentiment using a pretrained model.
- Balanced dataset:
  - 40,000 training samples
  - 10,000 testing samples
  - Equal distribution of positive and negative sentiments

### âœ… Preliminary Results
- High NER performance on key entity types: `PERSON`, `ORG`, `LOC`
- SA achieves **84% validation accuracy**
- Alert generation pipeline is planned but not yet deployed

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- Pretrained word2vec model (`GoogleNews-vectors-negative300`)
- Pretrained model weights (`best_model.pt` and `tag2idx.pkl` in the `models/` directory)

### Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/NerD.git
   cd NerD
   ```
   
2. Create a virtual environment and activate it (optional but recommended):
   ```bash
   python -m venv venv
   .\venv\Scripts\activate   # On Windows
   source venv/bin/activate # On macOS/Linux
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the app:
   ```bash
   python app.py
   ```

## ğŸš€ How to Use

The system exposes a simple web-based interface:

1. Upload a text post (e.g., news or social media content).
2. Upload a related image.
3. Click the **Analyze** button.

The app will:

- Generate a caption for the image.
- Perform NER + SA on the text + image caption.
- Display extracted entities and sentiment.

âš ï¸ **Make sure the pretrained models are present in the `models/` folder before running the app.**

## ğŸ“‚ Project Structure

```plaintext
NerD/
â”‚
â”œâ”€â”€ app.py                  # Entry point for the web interface
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # This file
â”‚
â”œâ”€â”€ data/                   # Datasets
â”‚   â”œâ”€â”€ train.tsv, test.tsv
â”‚   â””â”€â”€ multinerd/, NLP_Data/, nsa/
â”‚
â”œâ”€â”€ models/                 # Pretrained models
â”‚   â”œâ”€â”€ best_model.pt
â”‚   â”œâ”€â”€ tag2idx.pkl
â”‚   â””â”€â”€ w2v_model.bin
â”‚
â”œâ”€â”€ images/                 # Project-related images
â”‚   â””â”€â”€ banner.jpg, logo.jpg
â”‚
â”œâ”€â”€ docs/                   # Project documents and reports
â”‚
â””â”€â”€ src/                    # Source code
    â”œâ”€â”€ data.py
    â”œâ”€â”€ embeddings.py
    â”œâ”€â”€ evaluate.py
    â”œâ”€â”€ image_captioning.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ models.py
    â”œâ”€â”€ train.py
    â””â”€â”€ tsv_preprocessing.py
```


## ğŸ§  Technologies Used

### Frameworks & Libraries

- **PyTorch** â€“ for building and training the BiLSTM multitask model  
- **Transformers** â€“ Hugging Face library for image captioning  
- **Gensim** â€“ for loading pretrained word embeddings  
- **Gradio** â€“ for creating the interactive web interface  
- **Scikit-learn** â€“ for evaluation metrics  

### NLP & ML Techniques

- **BiLSTM Encoder**  
- **Multitask Learning**  
- **NER with Sequence Tagging**  
- **Binary Sentiment Classification**  
- **Image-to-Text Captioning**

## ğŸ™Œ Credits

This project was developed as part of the **Deep Learning + NLP** course at **Universidad Pontificia Comillas, ICAI**.

### Team Members

- **BeltrÃ¡n SÃ¡nchez Careaga**
- **Eugenio RibÃ³n Novoa**
- **Jorge Kindelan Navarro**
- **Ignacio Queipo de Llano PÃ©rez-GascÃ³n**

### Special Thanks To

- **Jaime Pizarroso Gonzalo** and **AndrÃ©s Occhipinti Liberman**, our professors, for their guidance and support throughout the course.  
- **Hugging Face** and **Gensim** communities for providing powerful pretrained models and tools.  
- **Open Source Contributors** whose libraries made this project possible.


<<<<<<< HEAD
=======

>>>>>>> dda5e554d43d74cf799e88029ad799f29bcb3756
