{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'O'), ('type', 'O'), ('locality', 'O'), ('is', 'O'), ('Kīlauea', 'B-LOC'), ('.', 'O')], [('Common', 'O'), ('components', 'O'), ('of', 'O'), ('the', 'O'), ('herb', 'O'), ('layer', 'O'), ('in', 'O'), ('bogs', 'O'), ('includes', 'O'), ('the', 'O'), ('carnivorous', 'O'), ('plants', 'O'), (':', 'O'), ('round-leaved', 'O'), ('sundew', 'O'), ('(', 'O'), ('\"', 'O'), ('Drosera', 'B-PLANT'), ('rotundifolia', 'I-PLANT'), ('\"', 'O'), (')', 'O'), (',', 'O'), ('and', 'O'), ('pitcher', 'O'), ('plant', 'O'), ('(', 'O'), ('\"', 'O'), ('Sarracenia', 'B-PLANT'), ('purpurea', 'I-PLANT'), ('\"', 'O'), (')', 'O'), ('.', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "def load_clean_conll(filepath):\n",
    "    data = []\n",
    "    sentence = []\n",
    "    \n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:  # Nueva frase\n",
    "                if sentence:\n",
    "                    data.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                tokens = line.split()\n",
    "                word, ner_label = tokens[1:3]  # Solo tomamos las primeras 2 columnas\n",
    "                sentence.append((word, ner_label))\n",
    "    \n",
    "    return data  # Lista de frases con solo palabra y NER\n",
    "\n",
    "dataset = load_clean_conll(\"../data/test_en.tsv\")\n",
    "print(dataset[:2])  # Ver las primeras frases\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las líneas del archivo TSV\n",
    "tsv_lines = []\n",
    "\n",
    "# Iteramos por cada oración en el dataset\n",
    "for sentence in dataset:\n",
    "    # Iteramos por cada palabra y su etiqueta NER\n",
    "    for word, label in sentence:\n",
    "        # Escribimos la palabra y su etiqueta NER en el formato adecuado\n",
    "        tsv_lines.append(f\"{word}\\t{label}\")\n",
    "    # Añadimos una línea vacía entre oraciones\n",
    "    tsv_lines.append(\"\")  \n",
    "\n",
    "# Guardamos el archivo TSV\n",
    "with open(\"test_data.tsv\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(tsv_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
