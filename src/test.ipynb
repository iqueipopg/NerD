{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de frases con sentimiento 0 (Negativo): 5000\n",
      "Cantidad de frases con sentimiento 1 (Neutral): 5000\n",
      "Cantidad de frases con sentimiento 2 (Positivo): 0\n",
      "Suma de frases:  10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo TSV\n",
    "with open(\"../data/test.tsv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Almacenar sentimientos por frase\n",
    "sentiment_counts = {0: 0, 1: 0, 2: 0}\n",
    "\n",
    "current_sentiment = None  # Variable para almacenar el sentimiento de la frase\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    \n",
    "    if line == \"\":  # Si es una línea vacía, se termina una frase\n",
    "        if current_sentiment is not None:\n",
    "            sentiment_counts[current_sentiment] += 1  # Contar solo una vez por frase\n",
    "        current_sentiment = None  # Reiniciar sentimiento para la nueva frase\n",
    "    else:\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) == 3:\n",
    "            _, _, sentiment = parts\n",
    "            current_sentiment = int(sentiment)  # Guardar el sentimiento de la frase actual\n",
    "\n",
    "# Asegurar que la última frase también se cuenta\n",
    "if current_sentiment is not None:\n",
    "    sentiment_counts[current_sentiment] += 1\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Cantidad de frases con sentimiento 0 (Negativo): {sentiment_counts[0]}\")\n",
    "print(f\"Cantidad de frases con sentimiento 1 (Neutral): {sentiment_counts[1]}\")\n",
    "print(f\"Cantidad de frases con sentimiento 2 (Positivo): {sentiment_counts[2]}\")\n",
    "\n",
    "print(\"Suma de frases: \", sum(sentiment_counts.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stealth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\Stealth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Stealth\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pretrained sentiment-analysis pipeline\n",
    "# By default, the pipeline uses a variant of BERT, called distilbert-base-uncased-finetuned-sst-2-english.\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_balanceado(input_file, output_file, max_por_clase=5000):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lineas = f.readlines()\n",
    "\n",
    "    positivas = []\n",
    "    negativas = []\n",
    "    frase_actual = []\n",
    "    sa_actual = None  # Sentiment Analysis de la frase\n",
    "\n",
    "    for linea in lineas:\n",
    "        if linea.strip() == \"\":\n",
    "            if frase_actual and sa_actual is not None:\n",
    "                if sa_actual == '1' and len(positivas) < max_por_clase:\n",
    "                    positivas.append(frase_actual)\n",
    "                elif sa_actual == '0' and len(negativas) < max_por_clase:\n",
    "                    negativas.append(frase_actual)\n",
    "\n",
    "                # Cortamos si ya tenemos todo\n",
    "                if len(positivas) == max_por_clase and len(negativas) == max_por_clase:\n",
    "                    break\n",
    "\n",
    "            frase_actual = []\n",
    "            sa_actual = None\n",
    "        else:\n",
    "            frase_actual.append(linea)\n",
    "            partes = linea.strip().split('\\t')\n",
    "            if len(partes) == 3:\n",
    "                sa = partes[2]\n",
    "                if sa_actual is None:\n",
    "                    sa_actual = sa  # Se toma el SA del primer token\n",
    "\n",
    "    # Guardamos las frases seleccionadas\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for frase in positivas + negativas:\n",
    "            f.writelines(frase)\n",
    "            f.write(\"\\n\")  # Línea vacía entre frases\n",
    "\n",
    "# Ejemplo de uso:\n",
    "extraer_balanceado(\"../data/output_test.tsv\", \"train_balanceado_10000.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-ANIM: 3914\n",
      "B-BIO: 45\n",
      "B-CEL: 672\n",
      "B-DIS: 3145\n",
      "B-EVE: 775\n",
      "B-FOOD: 2672\n",
      "B-INST: 95\n",
      "B-LOC: 18008\n",
      "B-MEDIA: 1821\n",
      "B-MYTH: 139\n",
      "B-ORG: 8542\n",
      "B-PER: 17473\n",
      "B-PLANT: 2501\n",
      "B-TIME: 726\n",
      "B-VEHI: 108\n",
      "I-ANIM: 1710\n",
      "I-BIO: 12\n",
      "I-CEL: 370\n",
      "I-DIS: 2092\n",
      "I-EVE: 1288\n",
      "I-FOOD: 973\n",
      "I-INST: 96\n",
      "I-LOC: 8005\n",
      "I-MEDIA: 2934\n",
      "I-MYTH: 31\n",
      "I-ORG: 11205\n",
      "I-PER: 18473\n",
      "I-PLANT: 857\n",
      "I-TIME: 556\n",
      "I-VEHI: 123\n",
      "O: 765213\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Lista de etiquetas posibles\n",
    "etiquetas = ['B-ANIM', 'B-BIO', 'B-CEL', 'B-DIS', 'B-EVE', 'B-FOOD', 'B-INST', 'B-LOC', 'B-MEDIA', 'B-MYTH',\n",
    "             'B-ORG', 'B-PER', 'B-PLANT', 'B-TIME', 'B-VEHI',\n",
    "             'I-ANIM', 'I-BIO', 'I-CEL', 'I-DIS', 'I-EVE', 'I-FOOD', 'I-INST', 'I-LOC', 'I-MEDIA', 'I-MYTH',\n",
    "             'I-ORG', 'I-PER', 'I-PLANT', 'I-TIME', 'I-VEHI',\n",
    "             'O']\n",
    "\n",
    "# Inicializa el contador\n",
    "conteo_etiquetas = Counter({etiqueta: 0 for etiqueta in etiquetas})\n",
    "\n",
    "# Ruta del archivo TSV\n",
    "ruta_tsv = \"../data/train.tsv\"  # cambia esto por la ruta de tu archivo\n",
    "\n",
    "# Leer archivo línea por línea\n",
    "with open(ruta_tsv, 'r', encoding='utf-8') as f:\n",
    "    for linea in f:\n",
    "        partes = linea.strip().split('\\t')\n",
    "        if len(partes) >= 2:\n",
    "            etiqueta = partes[1]\n",
    "            if etiqueta in conteo_etiquetas:\n",
    "                conteo_etiquetas[etiqueta] += 1\n",
    "\n",
    "# Mostrar el conteo\n",
    "for etiqueta, cantidad in conteo_etiquetas.items():\n",
    "    print(f\"{etiqueta}: {cantidad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos GloVe (100 dimensiones)\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")  # Solo se descarga una vez\n",
    "\n",
    "def sentence_to_embeddings(sentence, model=glove_model, dim=100):\n",
    "    \"\"\"\n",
    "    Converts a list of words into a list of GloVe embeddings.\n",
    "\n",
    "    Args:\n",
    "        sentence (list of str): Words in the sentence.\n",
    "        model: GloVe embedding model (gensim).\n",
    "        dim (int): Embedding dimension (default 100).\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: Embedding vectors for each word in the sentence.\n",
    "    \"\"\"\n",
    "    return [model[word] if word in model else np.zeros(dim) for word in sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_to_word(embedding, model, topn=1):\n",
    "    \"\"\"\n",
    "    Returns the most similar word(s) in the embedding space.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.ndarray): The embedding vector.\n",
    "        model: Gensim embedding model.\n",
    "        topn (int): Number of closest words to return.\n",
    "\n",
    "    Returns:\n",
    "        str or list: Closest word(s) to the given embedding.\n",
    "    \"\"\"\n",
    "    similar = model.similar_by_vector(embedding, topn=topn)\n",
    "    if topn == 1:\n",
    "        return similar[0][0]  # Return just the word\n",
    "    return [word for word, _ in similar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence has 6 embeddings\n",
      "First embedding shape: (100,)\n",
      "[-7.8748e-01 -8.8856e-02  7.4988e-01  5.2854e-01  1.5981e-03 -3.6809e-01\n",
      "  6.8798e-01  3.5121e-01  9.2334e-02 -1.8281e-01 -1.8805e-01  4.1248e-02\n",
      "  8.1858e-01  1.3372e-01  4.1265e-01 -9.0320e-01  2.7627e-01  1.0296e+00\n",
      "  2.3443e-02 -1.9191e-01  3.1135e-01 -2.4538e-01 -9.9959e-01  1.5308e-01\n",
      "  3.2938e-01  1.6536e+00 -4.5521e-01  6.1071e-01  2.5204e-01 -2.0436e-02\n",
      " -8.0607e-02 -5.4737e-01  2.1745e-01  3.2106e-01  1.6707e-01  2.0752e-01\n",
      "  2.5431e-01  1.0649e+00 -4.4017e-01 -5.2955e-01 -1.5593e+00  1.2501e-01\n",
      " -2.5508e-01  6.0666e-01 -8.8813e-02 -6.3777e-02 -1.0711e+00 -6.9952e-02\n",
      "  4.0339e-01 -1.4294e-01  2.0297e-01 -3.9117e-01  2.4745e-01  5.7762e-01\n",
      " -4.1829e-01 -2.2361e+00 -1.6890e-01  1.1592e+00  1.0618e+00  1.5931e-01\n",
      "  1.1075e-02  1.0953e+00  1.9624e-01 -9.1754e-02  2.9670e-01  3.2959e-01\n",
      "  5.3982e-01  2.3443e-01 -4.3785e-01 -2.2062e-02  4.4584e-01 -1.1955e-01\n",
      " -3.9980e-01 -3.9603e-01 -2.2918e-01 -2.6091e-01  4.0502e-01  7.2410e-02\n",
      " -1.6339e-01  8.8128e-02  2.5557e-01  5.7782e-01  6.4276e-02  1.9932e-01\n",
      " -5.2803e-01 -8.8585e-02  7.5005e-01 -3.9250e-01  1.4743e+00  7.2118e-02\n",
      " -2.8377e-01  4.6918e-01 -1.6116e-01  2.0557e-02 -1.6584e-02 -9.3574e-02\n",
      " -1.4756e+00 -1.6527e-01 -3.3802e-01 -8.6544e-01]\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"The\", \"cat\", \"jumps\", \"over\", \"the\", \"moon\"]\n",
    "embeddings = sentence_to_embeddings(sentence)\n",
    "\n",
    "print(f\"Sentence has {len(embeddings)} embeddings\")\n",
    "print(f\"First embedding shape: {embeddings[0].shape}\")\n",
    "print(embeddings[5])  # Vector for \"The\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models.keyedvectors import load_word2vec_format\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "SEED = 2222\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zQRH1zYBHJ_vU_uMkKvvvwQiZwP5N7wW\n",
      "From (redirected): https://drive.google.com/uc?id=1zQRH1zYBHJ_vU_uMkKvvvwQiZwP5N7wW&confirm=t&uuid=647c0076-b66f-4426-afe8-2fe033ae39c1\n",
      "To: c:\\Users\\Stealth\\OneDrive - Universidad Pontificia Comillas\\Documentos\\Uni\\3º iMAT\\CUATRI_2\\NLP\\NerD\\src\\NLP_DATA.zip\n",
      "100%|██████████| 1.65G/1.65G [01:17<00:00, 21.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# Google Drive direct download link\n",
    "url = 'https://drive.google.com/uc?id=1zQRH1zYBHJ_vU_uMkKvvvwQiZwP5N7wW'\n",
    "\n",
    "# Destination file name\n",
    "output = 'NLP_DATA.zip'\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Unzip the downloaded file\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "     zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings model to use in the assignment\n",
    "w2v_model = load_word2vec_format(\"../data/NLP_Data/embeddings/GoogleNews-vectors-negative300.bin.gz\", binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word, model, dim=300):\n",
    "    if word in model:\n",
    "        return model[word]\n",
    "    else:\n",
    "        return np.random.normal(scale=0.6, size=(dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.38742583e-01 -9.39425354e-01 -3.20494010e-01 -5.29401129e-01\n",
      "  1.36570074e-02 -5.53789374e-02 -6.05303501e-03  9.19039270e-01\n",
      "  1.34991894e-01  6.52069810e-01  5.52024565e-01  3.68742868e-01\n",
      " -1.17911365e-01 -4.27114177e-01 -3.47339154e-01 -3.37359029e-01\n",
      "  1.37578933e-01 -7.49205414e-01  5.15482149e-01 -8.51730107e-02\n",
      " -1.04567931e+00  1.18758180e-01 -6.15318232e-01  5.34403635e-01\n",
      "  9.17385131e-01 -3.94576576e-01 -2.88737364e-01 -1.11364102e+00\n",
      " -3.32575558e-01  7.04391557e-01  8.18952659e-01  1.02138948e+00\n",
      " -1.48072190e-01  3.17284560e-01 -7.27992932e-01  5.33845611e-01\n",
      " -2.59067852e-01  4.62576276e-01 -7.34260274e-01 -2.88338737e-03\n",
      "  1.08480422e-01  1.29728004e+00  6.15845949e-01 -1.71624919e-01\n",
      "  5.38487675e-01  3.28909387e-01  1.36484852e+00  8.16445843e-01\n",
      " -1.08793895e+00 -5.27753600e-02 -5.44989005e-01  5.57636689e-01\n",
      " -4.68559787e-01 -1.82336073e-01  1.17838256e-01  3.46739065e-01\n",
      " -2.07764583e-01  1.37985106e-01 -2.34717780e-01  2.96243550e-01\n",
      " -2.03276992e-01  9.64989846e-01 -3.78753817e-01 -3.05110773e-01\n",
      " -1.59414520e-01 -4.12468322e-01 -1.09245617e+00  6.82428738e-01\n",
      " -6.37838380e-01  1.68511748e-01  5.38560485e-01  5.11364699e-01\n",
      "  3.26249536e-01  1.15301959e+00  4.08644304e-01  9.62962245e-02\n",
      " -7.92041013e-01  1.57808916e-01  1.18857434e-01  1.98415292e-02\n",
      "  5.44584933e-01  4.68147796e-01 -8.85644467e-01  1.05167332e-01\n",
      "  5.65973802e-01  1.06330184e+00  8.26896521e-01 -1.95462803e-01\n",
      " -2.52759276e-01 -9.45471190e-02 -8.92923499e-01  5.73538448e-02\n",
      " -1.92902303e-01 -2.06760943e-01 -1.72902656e-02  1.47184704e+00\n",
      " -8.75288562e-01  7.11920668e-01 -1.04935224e-01  5.47935034e-01\n",
      " -5.00413761e-01 -1.39131668e-01  1.21127332e+00  5.92233664e-01\n",
      "  5.86324890e-01 -2.39054109e-01 -3.16706028e-01 -3.94027124e-01\n",
      " -4.10204652e-01  2.28439648e-01 -9.06445010e-02 -6.98410806e-01\n",
      " -1.96574283e-01 -6.03560856e-01 -7.56839771e-02  2.71588959e-01\n",
      "  6.14172354e-01 -1.69785779e-01 -5.56092161e-01 -3.73879847e-02\n",
      " -1.05826673e+00 -1.83538958e-01 -2.98269026e-01 -3.75016068e-01\n",
      " -3.81959881e-01  1.07712133e+00  1.78418123e-01  1.71566525e-01\n",
      "  7.02409236e-01  3.97520934e-01 -4.68746107e-01 -1.40902500e-01\n",
      "  1.11750256e-01 -1.74541855e-01 -6.06108692e-02  9.84207944e-02\n",
      "  3.29264568e-01 -3.76486150e-01 -2.21722811e-01  2.36076119e-01\n",
      "  3.59624250e-01  2.21382398e-01 -4.72881933e-01 -1.04956534e-01\n",
      " -3.60796382e-01 -7.19455299e-01 -4.25143290e-01  1.37525344e-01\n",
      " -1.68111574e-01 -8.81132799e-02 -2.34515080e-01 -5.60989443e-01\n",
      " -1.29372817e+00  3.74363372e-01 -3.34460449e-01 -6.45691933e-01\n",
      "  2.23669803e-01 -2.88400786e-01  3.94229490e-01 -8.80336134e-02\n",
      "  6.43445352e-01 -4.77176095e-01 -4.23319908e-01 -1.56113910e-01\n",
      " -3.21388736e-01  1.92871041e-01 -9.43567468e-01  3.37629545e-01\n",
      "  7.36119582e-01  5.68307997e-01 -2.62114009e-02  2.65007701e-01\n",
      "  5.36251217e-01 -8.78035185e-01  5.35579411e-01  6.67136514e-01\n",
      " -1.32402337e-01  1.07903728e-01  6.99739847e-01  9.33501029e-01\n",
      "  7.57212138e-01 -5.69147545e-01 -1.87363675e-01 -7.73520546e-01\n",
      " -4.36258429e-01  8.25229900e-01 -2.77968852e-01 -2.85872873e-01\n",
      " -5.24206777e-01 -2.67178170e-01 -2.65174318e-01  1.28646701e-01\n",
      "  7.90987565e-02  6.51578973e-01  7.18681290e-01 -3.16178834e-01\n",
      " -2.43139293e-04  3.05546547e-01  2.20246631e-01 -4.29382631e-01\n",
      "  5.99335133e-02 -1.16571391e+00 -2.62294919e-01  1.34480681e-01\n",
      "  7.57370118e-01  6.89695800e-01 -3.95544748e-01 -9.41796688e-02\n",
      " -1.91827816e-01  3.31799070e-01 -9.32485176e-01  1.50851071e-01\n",
      "  9.21873822e-01 -3.44694724e-01 -8.08607280e-01  1.09491846e-01\n",
      "  1.12431447e-01  3.48416271e-01 -1.58706868e-01 -3.29101707e-01\n",
      " -4.52902901e-01  2.08884511e-01  3.83637385e-01 -2.28739625e-01\n",
      " -8.21857007e-01 -6.42970130e-01 -8.73526055e-03  6.43714663e-01\n",
      " -2.31846192e-01 -4.87158164e-01 -2.42602983e-01  3.17176701e-01\n",
      "  7.89953668e-01 -2.68039217e-01  4.47912890e-01  2.91699821e-01\n",
      "  6.41121755e-01 -4.67418340e-02  2.34019967e-01  2.16931539e-01\n",
      " -9.01093908e-02  5.14370240e-01  2.15916134e-02 -4.08624695e-01\n",
      " -1.29226335e-01 -6.10317066e-01  1.91706891e-01 -6.46363420e-01\n",
      "  2.88089340e-02  3.35017174e-01 -6.18436726e-01 -4.14817924e-01\n",
      " -2.31645672e-01  1.12114711e+00 -1.31020519e-01  5.76662076e-01\n",
      "  6.20301486e-01  7.07532325e-01 -1.32543474e-01  5.85549247e-01\n",
      "  7.94271040e-02 -1.18205267e+00  1.31719238e-01  2.13202980e-01\n",
      " -3.04474625e-01  7.11610138e-01 -8.94763304e-01  4.03438440e-01\n",
      "  9.53685248e-01  2.35148153e-01 -2.92325516e-01 -1.22261810e-01\n",
      " -4.17665088e-01 -1.05763096e+00 -1.20524188e+00  3.67602455e-01\n",
      "  4.05071030e-01 -1.29246243e+00 -1.99848080e-01 -1.91987371e-01\n",
      " -6.33548647e-01 -1.94119136e-01  1.04833099e-01 -1.78066421e-01\n",
      "  4.44587338e-01 -2.26980538e-01 -4.09902777e-01  6.75855802e-01\n",
      "  2.30189061e-01 -1.55445814e-01 -1.30114400e-01 -4.38215406e-01\n",
      "  6.11512199e-01  2.51892068e-01  1.07748260e+00 -1.07122954e+00\n",
      "  2.80577276e-01  4.62659179e-01 -1.06370076e+00 -1.79221005e-01]\n"
     ]
    }
   ],
   "source": [
    "print(get_embedding(\"Kīlauea\", w2v_model))  # Should be (300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 300])\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"The\", \"cat\", \"jumps\", \"over\", \"the\", \"moon\"]\n",
    "embeddings = [get_embedding(word, w2v_model) for word in sentence]\n",
    "# convert to tensor\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float32) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
